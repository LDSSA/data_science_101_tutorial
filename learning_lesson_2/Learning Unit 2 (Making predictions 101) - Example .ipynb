{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Unit 2 - Making predictions 101 - Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports, feel free to ignore \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline \n",
    "\n",
    "from utils import plot_boundaries, get_ying_yang, scatterplot, plot_tree\n",
    "\n",
    "# In the odd chance that you have problems with graphviz, use the following instead: \n",
    "# from utils_safety import plot_boundaries, get_ying_yang, scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Binary Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed something about the exercise and examples: we are interested in _\"whether a mushroom is poisonous, or not\"_, and _\"Whether a Titanic passenger survived, or not\"_. \n",
    "\n",
    "This type of problem, where you are trying to predict which of 2 classes an observation belongs to, is called [Binary Classification](https://en.wikipedia.org/wiki/Binary_classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate this, we will be using an extremely simple dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = get_ying_yang()   # often df is used as shorthand for dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It just has 2 features, `a`, and `b`, and we will be trying to predict `c`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit of nomenclature: \n",
    "> **\"target\"**: that which we are trying to predict (in this case `c`). We often represent the target as `y`\n",
    "\n",
    "> **\"features\"**: that which we use to predict the target (in this case `a` and `b` are both features). We represent the features as `X`  \n",
    "\n",
    "> The **training set** is the data that will be used to train the model. Both `X_train` and `y_train` are part of the training set. \n",
    "\n",
    "> The **test set** is the data which is set aside to evaluate the model. It should always be different from the training set (we'll break that rule here to illustrate). As before, `X_test` and `y_test` will, repectively, be the features and target of the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://github.com/PedroGFonseca/how_to_learn_ds_meetup/raw/e553355800341008d524217912fe4ac0f2e07257/images/test_train.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we will call `a` and `b` features, and say that `c` is the target we are trying to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = simple[['a', 'b']]  # <-- the double brackets are because we are passing a list \n",
    "y_train = simple['c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are only in 2 dimentions, we can even \"cheat\" and look at the data with a quick scatterplot: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot(simple, 'a', 'b', 'c', small=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty simple, our classifier just needs to figure out the following: \n",
    "> the area to the \"left\" is 1  \n",
    "> the area to the \"right\" is 0  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Working with scikit classifiers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to do binary classification, but here we will focus on just 3 algorithms:\n",
    "\n",
    "- [Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) \n",
    "- [Decision Tree Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "- [KNN Classifier (\"K nearest neighbours\")](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions, we will be using the [scikit-learn library](http://scikit-learn.org/stable/index.html). It is generally the standart for getting started with Machine Learning in Python, and a number of production systems use it for its simplicity and excellent community. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API is extremely simple. When you have some features, and a target, you can fit a model by doing the following: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `model.fit(features, target)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what does it mean to `fit` (also known as training) a model? \n",
    "\n",
    "Essentially, you are showing it some training data (some features, and a target), and allowing it to set its parameters (there are exceptions, but we'll cover this later) so that it can predict new observations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot(simple, 'a', 'b', 'c', small=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest classifier to think about might be the [Logistic Regression](scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `fit`, `predict`, and `predict_proba`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ilustrate the use of the scikit API, we will use the Logistic Regression. \n",
    "\n",
    "We start by instanciating a Logistic regression. Nothing much happens at this stage: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instantiating a model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression() # just instanciating! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting a model: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we `fit` the model, passing it the `X_train`, and the `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(X=X_train, \n",
    "          y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logit is now fit, meaning that it has its parameters set, and is ready to make new predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Making predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make predictions, using the `predict` method \n",
    "\n",
    "*Note: remember, we should never predict the training set, we're doing that here just to illustrate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logit.predict(X_train)  # notice that we dont' need the target now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these predictions look like? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also predict probabilities, instead of predicting just 0 or 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_predictions = logit.predict_proba(X_train) # nomenclature becomes \"predict_proba\" \n",
    "\n",
    "print(proba_predictions[0:10])  # printing only the first 10 predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that each prediction is composed of two values, which add to one. \n",
    "\n",
    "That's because they are the _\"probability of being 0\"_ and the _\"probability of being 1\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simply get the probability of being 1, we can do the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_1 = proba_predictions[:,1]   # the syntax is a bit ugly, but it essentially means \"all entries, item 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the first 10 again: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_1[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So essentially if you threashold these at 0.5, you get the predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observing predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how well did our classifier do? \n",
    "\n",
    "Let's use a quick utility function, `plot_boundaries` to get an idea. Naturally this will only work in 2 dimentions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundaries(X_train, y_train, logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not particularly great. Too linear. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees are slightly more powerful models than the logistic regressions, because they aren't forced to be linear. Let's see how a tree predicts our dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=2)\n",
    "dt.fit(X_train, y_train)\n",
    "plot_boundaries(X_train, y_train, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly smarter. What if we change the hyper parameters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=6, min_samples_split=10)\n",
    "dt.fit(X_train, y_train)\n",
    "plot_boundaries(X_train, y_train, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest-neighbours rely on the idea that an observation can be predited by its `K` closest neighbours: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "plot_boundaries(X_train, y_train, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we make the `n_neighors` (number of neighbours) smaller?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "plot_boundaries(X_train, y_train, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we observe something interesting. We got more of our training set right, but we can tell by looking at it that something is wrong. How can we avoid this? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Overfitting and train-test-split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so up to now we've been predicting data the model has already seen, but what happens on data it doesn't know? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick reminder of how train and test sets work: \n",
    "![title](https://github.com/PedroGFonseca/how_to_learn_ds_meetup/raw/e553355800341008d524217912fe4ac0f2e07257/images/test_train.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break our dataset into training and test sets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder:\n",
    "# X_train: features to train on \n",
    "# y_train: targets (actual outcomes) to train on \n",
    "# X_test: features to test on \n",
    "# y_test: targets (actual outcomes) to test on \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(simple[['a', 'b']], \n",
    "                                                    simple['c'], \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to our KNN, and train on part of the dataset, and observe how it predicts the other part: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "plot_boundaries(X_test, y_test, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start to notice that there is some overfit. That red \"entrance\" was clearly something it saw on the training set, and learned \"too much\" from it. Let's increase the `n_neigbors` again: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "plot_boundaries(X_test, y_test, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! We can fight overfitting with sensible setting of hyper parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Evaluating our results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you now have an intuition as to why it is important to always train on your traninig set, and test on your test set. \n",
    "\n",
    "One trivial (but often too basic) way to evaluate your model is using accuracy (literally percentage of times you get the answer right): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy example \n",
    "predicted = [1, 0, 1]\n",
    "true = [1, 0, 0]\n",
    "print(accuracy_score(y_true=true, y_pred=predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate how well each of our classifiers does on unseen data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Logit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "print('Accuracy for %s was %0.2f' % ('Logistic Regression', accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern is always the same, so we might as well make this a function: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5, min_samples_split=5)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "print('Accuracy for %s was %0.2f' % ('Decision Tree Classifier', accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "print('Accuracy for %s was %0.2f' % ('K nearest neighbours', accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Using this on our mushrooms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by importing our \"`prepared_mushrooms`\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/prepared_mushrooms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a quick reminder of what the data looks like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows and columns? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Our mushroom dataset has %0.0f rows and %0.0f columns'  % (data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'is_poisonous'\n",
    "\n",
    "features = list(data.columns)\n",
    "features.remove(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: those who are comfortable with python should use a list comprehension, which is much more elegant:  \n",
    "    `features = [column for column in data.columns if column != target]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], \n",
    "                                                    data[target], \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the size of our new datasets? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's fit some models! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X_train, y_train)\n",
    "predictions = logit.predict(X_test)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "print('Accuracy for %s was %0.4f' % ('Logistic Regression', accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbours: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "print('Accuracy for %s was %0.4f' % ('K nearest neighbours', accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier(max_depth=3, min_samples_leaf=100)\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "predictions = decision_tree_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "print('Accuracy for %s was %0.4f' % ('Decision Tree Classifier', accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously we can and should try to tune the hyper parameters (`max depth`, `min_samples_leaf`, etc), but we'll do that in the exercise. You might have noticed that mushroons are relatively easy to predict. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus bit: interpreting models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One easy model to interpret (generally good to get first glances at datasets) is the Decision Tree Classifier:\n",
    "> \"Left\" means True     \n",
    "> The \"value\" is [_\"how many were in fact 0\"_, _\"how many were in fact 1\"_]  \n",
    "> The \"gini\" is a measure of \"impurity\". If the node has only 1 type, the gini is 0  \n",
    "> The \"samples\" is simply how many are in that node   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(tree_classifier=decision_tree_classifier, \n",
    "          X_train=X_train, \n",
    "          class_names=['Safe', 'Poisonous'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
