{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline \n",
    "\n",
    "from utils import plot_boundaries, get_linear_separable, get_circle, get_cross_data, scatterplot\n",
    "\n",
    "# In the odd chance that you have problems with graphviz, use the following instead: \n",
    "# from utils_safety import plot_boundaries, get_linear_separable, get_circle, get_cross_data, scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now it's your turn to make predictions! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a toy dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_data = get_linear_separable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the first few rows of the dataset, to have an idea what you are working with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the right method on the toy_data object to observe the first few lines \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instanciate a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate the right model (~1 line)\n",
    "logit = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The %s is now instantiated and ready to fit!' % logit.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Expceted output: The LogisticRegression is now instantiated and ready to fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break your toy data into X_train, y_train, X_test and y_test. \n",
    "\n",
    "> Your target should be `c`   \n",
    "> Your test_size 0.33  \n",
    "> Use random state 42 (so that you get the same result as us)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete code here (~1 line, or ~4 lines if you make it pretty)\n",
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Expected output: \n",
    "        X_train shape: (67, 2)\n",
    "        y_train shape: (67,)\n",
    "        X_test shape: (33, 2)\n",
    "        y_test shape: (33,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit your logistic regression to the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete code here (~1 line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The logit is fit, and has the following parameters: \\n    '\n",
    "      'beta0 =     %0.2f \\n    beta1 =     %0.2f\\n    '\n",
    "      'Intercept = %0.2f' % (logit.coef_[0][0], \n",
    "                             logit.coef_[0][1], \n",
    "                             logit.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Expected output: \n",
    "    \n",
    "        The logit is fit, and has the following parameters: \n",
    "            beta0 =     -2.74 \n",
    "            beta1 =     0.98\n",
    "            Intercept = 0.58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict the test set (just whether it is 1 or 0, no need for probabilities) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete code here (~1 line)\n",
    "predictions = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Expected output: [1 1 0 0 0 0 1 0 0 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate your performance, using the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete code here (~1 line)\n",
    "accuracy = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The logistic regression got an accuracy of %0.2f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Expected output: The logistic regression got an accuracy of 90.91%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a function to do this all in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # fit the model (~1 line)\n",
    "    \n",
    "\n",
    "    # make predictions (~1 line)\n",
    "    predictions = \n",
    "    \n",
    "    # calculate the accuracy (~1 line )\n",
    "    accuracy = \n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "accuracy = train_and_test_model(model=decision_tree, \n",
    "                                X_train=X_train,\n",
    "                                y_train=y_train,\n",
    "                                X_test=X_test,\n",
    "                                y_test=y_test,)\n",
    "\n",
    "print('The Decision Tree Classifier got an accuracy of %0.2f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the DecisionTreeClassifier's hyper-parameters (max_depth should be enough) to get a better performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete code here (~1 line)\n",
    "decision_tree_improved = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = train_and_test_model(model=decision_tree_improved, \n",
    "                                X_train=X_train,\n",
    "                                y_train=y_train,\n",
    "                                X_test=X_test,\n",
    "                                y_test=y_test,)\n",
    "\n",
    "print('The Decision Tree Classifier got an accuracy of %0.2f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Expected output: The Decision Tree Classifier got an accuracy of 93.94% \n",
    "    Note: you can get above this value, but this is an easy one to get "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, for a proper challenge! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load `titanic_train.csv` from the data folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete code here (~1 line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a classifier on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete code here (~1 line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load `titanic_test.csv` from the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete code here (~1 line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate your performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete code here (~1 line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, try to improve your performance. Maybe use different classifiers, or tweak their hyper parameters! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete code here (as many lines as needed, this is now data science!)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
